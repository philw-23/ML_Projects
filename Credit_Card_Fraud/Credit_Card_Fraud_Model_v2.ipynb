{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa6fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "cores_to_use = mp.cpu_count() - 1 # Use one less core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2425319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific packages\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Dataset object\n",
    "# File path is path to data\n",
    "# init_splitter is a CV splitter\n",
    "class CCDataset():\n",
    "    def __init__(self, file_path): \n",
    "        self.file_path = file_path # Initial file load\n",
    "        self.X, self.y = self.load_dataset() # Data object\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        data_raw = pd.read_csv(self.file_path) # Read in data\n",
    "        # If there were other necessary preprocessing steps, would put them here\n",
    "        # In this case there isn't\n",
    "        # Also Note: We would want Scaling steps to be separate\n",
    "            # And Normalize on Train Data, apply same scaler to test data (not a new one)\n",
    "        data_np = data_raw.values # Return only the data object\n",
    "        X, y = data_np[:, :-1], data_np[:, -1] # Data and labels\n",
    "        return X, y\n",
    "    \n",
    "    # reccomended accuracy function for heavily imbalanced data\n",
    "    def pr_auc(self, y_true, preds):\n",
    "        p, r, _ = precision_recall_curve(y_true, preds) # Returns a curve set\n",
    "        return auc(r, p) # returns area under the curve\n",
    "        \n",
    "    # Function for evaluating a model using pr_auc\n",
    "    def evaluate_model(self, model, X, y):\n",
    "        # The data splits we want to use\n",
    "        data_splits = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        # Generates a callable scoring function from custom loss func\n",
    "        # Thus you can pass it to a grid search or something of that nature to compare different runs/models\n",
    "        # NOTE: if I wanted to do a grid/random search, I could similarly pass the scorer/cv to those intializers!\n",
    "        scorer = make_scorer(self.pr_auc, needs_proba=True)\n",
    "        model_scores = cross_val_score(model, X, y, \n",
    "                                       scoring=scorer, # What method you are using for calculating cores\n",
    "                                       cv=data_splits, # How you are going to be generating your splits\n",
    "                                       n_jobs = cores_to_use) # Number of processes\n",
    "        \n",
    "        return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e53ce418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "# models = {'Decision Tree':DecisionTreeClassifier(),\n",
    "#          'Random Forest':RandomForestClassifier(),\n",
    "#          'Extra Trees':ExtraTreesClassifier(),\n",
    "#          'Bagging':BaggingClassifier()}\n",
    "models = {'Extra Trees':ExtraTreesClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bace52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset object and execute\n",
    "import time\n",
    "\n",
    "# Create Dataset Object\n",
    "cc_dat = CCDataset('./creditcard.csv')\n",
    "\n",
    "# Takes in models to consider, as well as a CCDataset object\n",
    "def run_models(models, cc_dataset):\n",
    "    results = []\n",
    "    for key, model in models.items():\n",
    "        start = time.time()\n",
    "        scores = cc_dataset.evaluate_model(model, cc_dataset.X, cc_dataset.y)\n",
    "        results.append(scores)\n",
    "        end = time.time()\n",
    "        run_time = str(round(end - start, 3))\n",
    "        m = str(round(np.mean(scores), 3))\n",
    "        s = str(round(np.std(scores), 3))\n",
    "        print('Model = ' + key + ': ' + m + ', ' + s + \\\n",
    "              ', run_time = ' + run_time + 's')\n",
    "        \n",
    "run_models(models, cc_dat) # Run set of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3a334",
   "metadata": {},
   "source": [
    "### Results\n",
    "* Extra trees performed the best\n",
    "* Can we get better performance that the default values\n",
    "    * Let's do a random search\n",
    "    * Might make the most sense to make a class function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search on extra trees classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
