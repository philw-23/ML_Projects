{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9ba7561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "cores_to_use = mp.cpu_count() - 1 # Use one less core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "472c6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific packages\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Dataset object\n",
    "# File path is path to data\n",
    "# init_splitter is a CV splitter\n",
    "class CCDataset():\n",
    "    def __init__(self, file_path, init_splitter): \n",
    "        self.file_path = file_path # Initial file load\n",
    "        self.X, self.y = self.load_dataset() # Data object\n",
    "        self.splitter = init_splitter\n",
    "        \n",
    "    def load_dataset(self):\n",
    "        data_raw = pd.read_csv(self.file_path) # Read in data\n",
    "        # If there were other necessary preprocessing steps, would put them here\n",
    "        # In this case there isn't\n",
    "        # Also Note: We would want Scaling steps to be separate\n",
    "            # And Normalize on Train Data, apply same scaler to test data (not a new one)\n",
    "        data_np = data_raw.values # Return only the data object\n",
    "        X, y = data_np[:, :-1], data_np[:, -1] # Data and labels\n",
    "        return X, y\n",
    "    \n",
    "    # reccomended accuracy function for heavily imbalanced data\n",
    "    def pr_auc(self, y_true, preds):\n",
    "        p, r, _ = precision_recall_curve(y_true, preds) # Returns a curve set\n",
    "        return auc(r, p) # returns area under the curve\n",
    "    \n",
    "    # Function for updating CV Splitter to something new\n",
    "    def make_splitter(self, cv_splitter):\n",
    "        return cv_splitter\n",
    "            \n",
    "    # Grid search for optimization\n",
    "    def run_grid_search(self, model, parameters):\n",
    "        # Build scorer\n",
    "        scorer = make_scorer(self.pr_auc, needs_proba=True)\n",
    "        # Generate Grid Search Object\n",
    "        grid = GridSearchCV(estimator=model, param_grid=parameters,\n",
    "                           n_jobs=cores_to_use, cv=self.splitter,\n",
    "                           scoring=scorer)\n",
    "        # Fit Data\n",
    "        grid.fit(self.X, self.y)\n",
    "        return grid\n",
    "        \n",
    "    # Function for evaluating a model using pr_auc\n",
    "    def evaluate_model(self, model, X, y):\n",
    "        # The data splits we want to use\n",
    "        # Generates a callable scoring function from custom loss func\n",
    "        # Thus you can pass it to a grid search or something of that nature to compare different runs/models\n",
    "        # NOTE: if I wanted to do a grid/random search, I could similarly pass the scorer/cv to those intializers!\n",
    "        scorer = make_scorer(self.pr_auc, needs_proba=True)\n",
    "        model_scores = cross_val_score(model, X, y, \n",
    "                                       scoring=scorer, # What method you are using for calculating cores\n",
    "                                       cv=self.splitter, # How you are going to be generating your splits\n",
    "                                       n_jobs = cores_to_use) # Number of processes\n",
    "        \n",
    "        return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39fd95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "models = {'Decision Tree':DecisionTreeClassifier(),\n",
    "         'Random Forest':RandomForestClassifier(),\n",
    "         'Extra Trees':ExtraTreesClassifier(),\n",
    "         'Bagging':BaggingClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdb0bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset object and execute\n",
    "import time\n",
    "\n",
    "# Create Dataset Object\n",
    "splitter = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "cc_dat = CCDataset('./creditcard.csv', splitter)\n",
    "\n",
    "# Takes in models to consider, as well as a CCDataset object\n",
    "def run_models(models, cc_dataset):\n",
    "    results = []\n",
    "    for key, model in models.items():\n",
    "        start = time.time()\n",
    "        scores = cc_dataset.evaluate_model(model, cc_dataset.X, cc_dataset.y)\n",
    "        results.append(scores)\n",
    "        end = time.time()\n",
    "        run_time = str(round(end - start, 3))\n",
    "        m = str(round(np.mean(scores), 3))\n",
    "        s = str(round(np.std(scores), 3))\n",
    "        print('Model = ' + key + ': ' + m + ', ' + s + \\\n",
    "              ', run_time = ' + run_time + 's')\n",
    "        \n",
    "run_models(models, cc_dat) # Run set of models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c3ba01",
   "metadata": {},
   "source": [
    "### Results\n",
    "* Extra trees performed the best\n",
    "* Can we get better performance that the default values\n",
    "    * Let's do a random search\n",
    "    * Might make the most sense to make a class function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7142b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
       "             estimator=ExtraTreesClassifier(), n_jobs=11,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring=make_scorer(pr_auc, needs_proba=True))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search on extra trees classifier\n",
    "# This is a test - not intended to tune parameters\n",
    "param_grid = {\n",
    "    'n_estimators':[50, 100, 200],\n",
    "    'bootstrap':[True, False]\n",
    "}\n",
    "\n",
    "grid_results = cc_dat.run_grid_search(models['Extra Trees'], param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "995f6c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scoring': make_scorer(pr_auc, needs_proba=True),\n",
       " 'estimator': ExtraTreesClassifier(),\n",
       " 'n_jobs': 11,\n",
       " 'refit': True,\n",
       " 'cv': RepeatedStratifiedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
       " 'verbose': 0,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'error_score': nan,\n",
       " 'return_train_score': False,\n",
       " 'param_grid': {'n_estimators': [50, 100, 200], 'bootstrap': [True, False]},\n",
       " 'multimetric_': False,\n",
       " 'best_index_': 5,\n",
       " 'best_score_': 0.8654374524055811,\n",
       " 'best_params_': {'bootstrap': False, 'n_estimators': 200},\n",
       " 'best_estimator_': ExtraTreesClassifier(n_estimators=200),\n",
       " 'refit_time_': 44.34875154495239,\n",
       " 'scorer_': make_scorer(pr_auc, needs_proba=True),\n",
       " 'cv_results_': {'mean_fit_time': array([ 40.11501992,  84.0108492 , 166.00723124,  63.03104612,\n",
       "         124.25726318, 229.02655768]),\n",
       "  'std_fit_time': array([ 1.23394263,  2.35385305,  5.54593163,  2.67439392,  3.18350877,\n",
       "         29.34928   ]),\n",
       "  'mean_score_time': array([0.18196044, 0.36727539, 0.7243084 , 0.20792242, 0.40488521,\n",
       "         0.7518172 ]),\n",
       "  'std_score_time': array([0.00696583, 0.01604797, 0.03404516, 0.01087547, 0.01197773,\n",
       "         0.09374823]),\n",
       "  'param_bootstrap': masked_array(data=[True, True, True, False, False, False],\n",
       "               mask=[False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[50, 100, 200, 50, 100, 200],\n",
       "               mask=[False, False, False, False, False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'bootstrap': True, 'n_estimators': 50},\n",
       "   {'bootstrap': True, 'n_estimators': 100},\n",
       "   {'bootstrap': True, 'n_estimators': 200},\n",
       "   {'bootstrap': False, 'n_estimators': 50},\n",
       "   {'bootstrap': False, 'n_estimators': 100},\n",
       "   {'bootstrap': False, 'n_estimators': 200}],\n",
       "  'split0_test_score': array([0.84594266, 0.84837901, 0.83602185, 0.84112906, 0.84725181,\n",
       "         0.84106465]),\n",
       "  'split1_test_score': array([0.80467554, 0.80923966, 0.806924  , 0.81676338, 0.81649662,\n",
       "         0.81344163]),\n",
       "  'split2_test_score': array([0.88087968, 0.89305226, 0.8912849 , 0.89072647, 0.89151642,\n",
       "         0.8933997 ]),\n",
       "  'split3_test_score': array([0.86660504, 0.86257978, 0.86251487, 0.8602934 , 0.85769175,\n",
       "         0.86150357]),\n",
       "  'split4_test_score': array([0.86545564, 0.86331035, 0.86451278, 0.8729595 , 0.871032  ,\n",
       "         0.86741308]),\n",
       "  'split5_test_score': array([0.88299672, 0.87615257, 0.87960419, 0.89093855, 0.8904037 ,\n",
       "         0.8940454 ]),\n",
       "  'split6_test_score': array([0.92684485, 0.934626  , 0.92609901, 0.93719812, 0.93052135,\n",
       "         0.93567048]),\n",
       "  'split7_test_score': array([0.82433706, 0.83445919, 0.82514982, 0.82025302, 0.83278841,\n",
       "         0.83398227]),\n",
       "  'split8_test_score': array([0.82722998, 0.83213352, 0.83808668, 0.83156328, 0.84381667,\n",
       "         0.84933151]),\n",
       "  'split9_test_score': array([0.86266317, 0.85567971, 0.86394495, 0.86751654, 0.86864791,\n",
       "         0.86037078]),\n",
       "  'split10_test_score': array([0.8130106 , 0.80994005, 0.80256406, 0.81912476, 0.82045319,\n",
       "         0.81562863]),\n",
       "  'split11_test_score': array([0.85602012, 0.87264015, 0.85897323, 0.87865425, 0.87819985,\n",
       "         0.87101039]),\n",
       "  'split12_test_score': array([0.87509664, 0.87424055, 0.87307824, 0.8824376 , 0.87588292,\n",
       "         0.87553573]),\n",
       "  'split13_test_score': array([0.84015851, 0.85309688, 0.8466475 , 0.84707453, 0.84104294,\n",
       "         0.85199923]),\n",
       "  'split14_test_score': array([0.90659195, 0.90678045, 0.89869263, 0.89692283, 0.89910704,\n",
       "         0.90298926]),\n",
       "  'split15_test_score': array([0.88256478, 0.88275993, 0.8884019 , 0.87466299, 0.8829994 ,\n",
       "         0.89587955]),\n",
       "  'split16_test_score': array([0.79661008, 0.79531786, 0.79183102, 0.80912307, 0.80690662,\n",
       "         0.79838206]),\n",
       "  'split17_test_score': array([0.89537561, 0.90078924, 0.90082232, 0.89327845, 0.90114848,\n",
       "         0.90725618]),\n",
       "  'split18_test_score': array([0.87787552, 0.87472262, 0.87320343, 0.87688225, 0.87755322,\n",
       "         0.88983987]),\n",
       "  'split19_test_score': array([0.86185015, 0.84242101, 0.85855198, 0.84560171, 0.85551602,\n",
       "         0.86215515]),\n",
       "  'split20_test_score': array([0.8845097 , 0.89546641, 0.89186598, 0.8889944 , 0.90833552,\n",
       "         0.90172099]),\n",
       "  'split21_test_score': array([0.93374304, 0.93856138, 0.93535735, 0.93423507, 0.93669108,\n",
       "         0.94108715]),\n",
       "  'split22_test_score': array([0.8036214 , 0.79751774, 0.81292135, 0.78021374, 0.82023809,\n",
       "         0.80627212]),\n",
       "  'split23_test_score': array([0.9239574 , 0.9220226 , 0.92143384, 0.93439426, 0.93276628,\n",
       "         0.9393914 ]),\n",
       "  'split24_test_score': array([0.86759296, 0.87180289, 0.87127498, 0.87518447, 0.87360778,\n",
       "         0.87060345]),\n",
       "  'split25_test_score': array([0.82172426, 0.81577613, 0.81713576, 0.81907393, 0.80839965,\n",
       "         0.82541226]),\n",
       "  'split26_test_score': array([0.87935494, 0.8850523 , 0.89298735, 0.87757612, 0.87485787,\n",
       "         0.87799961]),\n",
       "  'split27_test_score': array([0.91164885, 0.90516709, 0.90880229, 0.91446719, 0.91372617,\n",
       "         0.92063393]),\n",
       "  'split28_test_score': array([0.81106515, 0.81964785, 0.81367403, 0.81670799, 0.81946074,\n",
       "         0.81653721]),\n",
       "  'split29_test_score': array([0.73295199, 0.73647776, 0.74131537, 0.74190676, 0.74769128,\n",
       "         0.74256633]),\n",
       "  'mean_test_score': array([0.85876513, 0.8603271 , 0.85978926, 0.86119526, 0.86415836,\n",
       "         0.86543745]),\n",
       "  'std_test_score': array([0.04419599, 0.04469203, 0.0438383 , 0.04485738, 0.0425607 ,\n",
       "         0.04525415]),\n",
       "  'rank_test_score': array([6, 4, 5, 3, 2, 1])},\n",
       " 'n_splits_': 30}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Grid Results\n",
    "grid_results.__dict__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
